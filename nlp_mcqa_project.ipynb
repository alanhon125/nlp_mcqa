{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_mcqa_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fivORmU9vRF"
      },
      "source": [
        "# **Implement BERT classifier for MCQA on DREAM, RACE, MCTest datasets**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xc0vhr167Rw2"
      },
      "source": [
        "Please upload your master folder to your Google Drive before start!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBGzeq03MB3_"
      },
      "source": [
        "To make the other files in your Google drive folder available, you can mount your Google drive with:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbTZQyP9a3Xy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "446d8cbe-9195-4299-8dad-76ec3179b9e7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_5MSvA8MTTe"
      },
      "source": [
        "Then you should change directory, by the following command before start:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THjgpA22AYxk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c601f2ba-c212-44df-c45b-5e6a0774451a"
      },
      "source": [
        "%cd /content/drive/MyDrive/Colab\\ Notebooks/nlp_MCQA_project"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/MMM-MCQA-master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2g9nfiPXMfCw"
      },
      "source": [
        "Check your present working directory with:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDQhjjuDD7dk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9c194424-ff73-46e2-c164-9153ecfc0955"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks/MMM-MCQA-master'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmWQa-zjMbuu"
      },
      "source": [
        "All five MCQA datasets are put in the folder \"data\" and to unzip the RACE data, run the following command"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeQvKkgUBw_T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4607993a-b976-4027-8cef-22b01092ab3b"
      },
      "source": [
        "!tar -xf /content/drive/MyDrive/Colab\\ Notebooks/MMM-MCQA-master/data/RACE.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhz5zfKGMlHQ"
      },
      "source": [
        "Google Colab doesn't have boto3 library (used to access files from S3 directly), install it with following before start:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRGxJkUjGEEZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00b4baad-61f0-4578-8357-5ddea88e0c0f"
      },
      "source": [
        "pip install boto3"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/1e/570e2446e97bac3d348d0bc6cbf8ac28997ddbef3d97c052f1c476ff48bb/boto3-1.17.49.tar.gz (99kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 8.2MB/s \n",
            "\u001b[?25hCollecting botocore<1.21.0,>=1.20.49\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/59/6e28ce58206039ad2592992b75ee79a8f9dbc902a9704373ddacc4f96300/botocore-1.20.49-py2.py3-none-any.whl (7.4MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4MB 16.3MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/14/0b4be62b65c52d6d1c442f24e02d2a9889a73d3c352002e14c70f84a679f/s3transfer-0.3.6-py2.py3-none-any.whl (73kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.4MB/s \n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/c6/d3e3abe5b4f4f16cf0dfc9240ab7ce10c2baa0e268989a4e3ec19e90c84e/urllib3-1.26.4-py2.py3-none-any.whl (153kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 43.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.49->boto3) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.49->boto3) (1.15.0)\n",
            "Building wheels for collected packages: boto3\n",
            "  Building wheel for boto3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for boto3: filename=boto3-1.17.49-py2.py3-none-any.whl size=128780 sha256=502884f544ad4e4bc89df166ba36798f136500e59a5189323c1f4ba1926a6887\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/b1/01/9e2fc2b05c6a254c29192a33e40dec0486588261372745ab27\n",
            "Successfully built boto3\n",
            "\u001b[31mERROR: requests 2.23.0 has requirement urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you'll have urllib3 1.26.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: jmespath, urllib3, botocore, s3transfer, boto3\n",
            "  Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed boto3-1.17.49 botocore-1.20.49 jmespath-0.10.0 s3transfer-0.3.6 urllib3-1.26.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8DaIXnf9NO2"
      },
      "source": [
        "# **Enabling and testing the GPU**\n",
        "\n",
        "First, you'll need to enable GPUs for the notebook:\n",
        "\n",
        "Navigate to Edit→Notebook Settings\n",
        "select GPU from the Hardware Accelerator drop-down"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myPNdjYf6HPR"
      },
      "source": [
        "Run BERT with command:  \n",
        "\n",
        "```\n",
        "!python run_classifier_bert_exe.py --task_name {task_name} --bert_model_dir {BERT_DIR} --per_gpu_train_batch_size {per_gpu_train_batch_size} --gradient_accumulation_steps {gradient_accumulation_steps}\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c0F3YYR8wxu"
      },
      "source": [
        "(If you fail to execute the program because out of GPU memory, please reduce your Batch_size and/or max_sequence_length in utils_glue.py)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkaYDT7KyzoN"
      },
      "source": [
        "Run below code for modified code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YN5Q-tg7uind",
        "outputId": "5f0fb2a3-d22c-47fe-8722-70b77864e894"
      },
      "source": [
        "!python run_bert.py "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.4) or chardet (3.0.4) doesn't match a supported version!\n",
            "  RequestsDependencyWarning)\n",
            "04/10/2021 13:07:40 - INFO - __main__ -   device cuda n_gpu 1 distributed training False\n",
            "04/10/2021 13:07:40 - INFO - pytorch_pretrained_bert.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt not found in cache, downloading to /tmp/tmp2ntfhebl\n",
            "100% 231508/231508 [00:00<00:00, 15072722.52B/s]\n",
            "04/10/2021 13:07:40 - INFO - pytorch_pretrained_bert.file_utils -   copying /tmp/tmp2ntfhebl to cache at /root/.cache/torch/pytorch_pretrained_bert/9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "04/10/2021 13:07:40 - INFO - pytorch_pretrained_bert.file_utils -   creating metadata file for /root/.cache/torch/pytorch_pretrained_bert/9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "04/10/2021 13:07:40 - INFO - pytorch_pretrained_bert.file_utils -   removing temp file /tmp/tmp2ntfhebl\n",
            "04/10/2021 13:07:40 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_pretrained_bert/9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "04/10/2021 13:07:41 - INFO - pytorch_pretrained_bert.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-pytorch_model.bin not found in cache, downloading to /tmp/tmpcpl0pfr0\n",
            "100% 1344997306/1344997306 [00:22<00:00, 60425534.95B/s]\n",
            "04/10/2021 13:08:03 - INFO - pytorch_pretrained_bert.file_utils -   copying /tmp/tmpcpl0pfr0 to cache at /root/.cache/torch/pytorch_pretrained_bert/54da47087cc86ce75324e4dc9bbb5f66c6e83a7c6bd23baea8b489acc8d09aa4.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6\n",
            "04/10/2021 13:08:17 - INFO - pytorch_pretrained_bert.file_utils -   creating metadata file for /root/.cache/torch/pytorch_pretrained_bert/54da47087cc86ce75324e4dc9bbb5f66c6e83a7c6bd23baea8b489acc8d09aa4.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6\n",
            "04/10/2021 13:08:17 - INFO - pytorch_pretrained_bert.file_utils -   removing temp file /tmp/tmpcpl0pfr0\n",
            "04/10/2021 13:08:17 - INFO - pytorch_pretrained_bert.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json not found in cache, downloading to /tmp/tmpbtpvlr1k\n",
            "100% 434/434 [00:00<00:00, 475902.73B/s]\n",
            "04/10/2021 13:08:17 - INFO - pytorch_pretrained_bert.file_utils -   copying /tmp/tmpbtpvlr1k to cache at /root/.cache/torch/pytorch_pretrained_bert/6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.788fed32bb8481a9b15ce726d41c53d5d5066b04c667e34ce3a7a3826d1573d8\n",
            "04/10/2021 13:08:17 - INFO - pytorch_pretrained_bert.file_utils -   creating metadata file for /root/.cache/torch/pytorch_pretrained_bert/6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.788fed32bb8481a9b15ce726d41c53d5d5066b04c667e34ce3a7a3826d1573d8\n",
            "04/10/2021 13:08:17 - INFO - pytorch_pretrained_bert.file_utils -   removing temp file /tmp/tmpbtpvlr1k\n",
            "04/10/2021 13:08:17 - INFO - pytorch_pretrained_bert.modeling -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_pretrained_bert/54da47087cc86ce75324e4dc9bbb5f66c6e83a7c6bd23baea8b489acc8d09aa4.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6\n",
            "04/10/2021 13:08:17 - INFO - pytorch_pretrained_bert.modeling -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json from cache at /root/.cache/torch/pytorch_pretrained_bert/6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.788fed32bb8481a9b15ce726d41c53d5d5066b04c667e34ce3a7a3826d1573d8\n",
            "04/10/2021 13:08:17 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "04/10/2021 13:08:33 - INFO - pytorch_pretrained_bert.modeling -   Randomly initialize the top level classifiers!\n",
            "04/10/2021 13:08:33 - INFO - pytorch_pretrained_bert.modeling -   Failed for Randomly initialize the top level classifiers!\n",
            "04/10/2021 13:08:33 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForMultipleChoice_MT_general not initialized from pretrained model: ['classifiers.0.weight', 'classifiers.0.bias']\n",
            "04/10/2021 13:08:33 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForMultipleChoice_MT_general: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "04/10/2021 13:09:18 - INFO - __main__ -   Loading features from cached file data/RACE/cached_dev_bert-large-uncased_512_race\n",
            "04/10/2021 13:09:27 - INFO - __main__ -   ***** Running evaluation for race on dev for epoch 3.0 *****\n",
            "04/10/2021 13:09:27 - INFO - __main__ -     Num examples = 4887\n",
            "04/10/2021 13:09:27 - INFO - __main__ -     Batch size = 8\n",
            "Evaluating: 100% 611/611 [43:22<00:00,  4.26s/it]\n",
            "04/10/2021 13:52:49 - INFO - __main__ -   ***** Eval results for race on dev for epoch 3.0 *****\n",
            "04/10/2021 13:52:49 - INFO - __main__ -     acc = 0.6251278903212605\n",
            "04/10/2021 13:52:49 - INFO - __main__ -   \n",
            "\n",
            "04/10/2021 13:54:05 - INFO - __main__ -   Creating features from dataset file at data/RACE\n",
            "04/10/2021 14:02:58 - INFO - utils_glue -   Writing example 0 of 27264\n",
            "04/10/2021 14:03:45 - INFO - utils_glue -   Writing example 10000 of 27264\n",
            "04/10/2021 14:04:32 - INFO - utils_glue -   Writing example 20000 of 27264\n",
            "04/10/2021 14:04:56 - INFO - __main__ -   Saving features into cached file data/RACE/cached_test_bert-large-uncased_512_race\n",
            "04/10/2021 14:05:09 - INFO - __main__ -   ***** Running evaluation for race on test for epoch 3.0 *****\n",
            "04/10/2021 14:05:09 - INFO - __main__ -     Num examples = 6816\n",
            "04/10/2021 14:05:09 - INFO - __main__ -     Batch size = 8\n",
            "Evaluating: 100% 852/852 [1:00:31<00:00,  4.26s/it]\n",
            "04/10/2021 15:05:41 - INFO - __main__ -   ***** Eval results for race on test for epoch 3.0 *****\n",
            "04/10/2021 15:05:41 - INFO - __main__ -     acc = 0.6026995305164319\n",
            "04/10/2021 15:05:41 - INFO - __main__ -   \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4MJUng2ygSa"
      },
      "source": [
        "Run the below code for original run_classifier_bert_exe.py:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFXoZDW8L-w_"
      },
      "source": [
        "`python run_classifier_bert_exe.py TASK_NAME MODEL_DIR BATCH_SIZE_PER_GPU GRADIENT_ACCUMULATION_STEPS`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YS4omFYoL7MG"
      },
      "source": [
        "Here we explain each required argument in details:\n",
        "\n",
        "**TASK_NAME:** It can be a single task or multiple tasks. If a single task, the options are: dream, race, toefl, mcscript, mctest160, mctest500, mnli, snli, etc. Multiple tasks can be any combinations of those above-mentioned single tasks. For example, if you want to train a multi-task model on the dream and race tasks together, then this variable should be set as \"dream,race\".\n",
        "\n",
        "**MODEL_DIR:** Model would be initialized by the parameters stored in this directory.\n",
        "\n",
        "**BATCH_SIZE_PER_GPU: **Batch size of data in a single GPU.\n",
        "\n",
        "**GRADIENT_ACCUMULATION_STEPS: **How many steps to accumulate the gradients for one step of back-propagation.\n",
        "One note: the effective batch size for training is important, which is the product of three variables: \n",
        "\n",
        "**BATCH_SIZE_PER_GPU, NUM_OF_GPUs, and GRADIENT_ACCUMULATION_STEPS. **\n",
        "\n",
        "n my experience, it should be at least higher than 12 and 24 would be great.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuIfTO8eBGLI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a705b8fb-e2f7-44e5-8e5d-6ce7f761ece5"
      },
      "source": [
        "!python run_classifier_bert_exe.py dream \"tmp/\" 8 2 --do_eval"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.4) or chardet (3.0.4) doesn't match a supported version!\n",
            "  RequestsDependencyWarning)\n",
            "04/10/2021 12:16:25 - INFO - __main__ -   device cuda n_gpu 1 distributed training False\n",
            "Output directory (tmp/dream_tmp/) already exists and is not empty.\n",
            "04/10/2021 12:16:25 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file tmp/vocab.txt\n",
            "04/10/2021 12:16:25 - INFO - pytorch_pretrained_bert.modeling -   loading weights file tmp/pytorch_model.bin\n",
            "04/10/2021 12:16:25 - INFO - pytorch_pretrained_bert.modeling -   loading configuration file tmp/config.json\n",
            "04/10/2021 12:16:25 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "04/10/2021 12:16:34 - INFO - pytorch_pretrained_bert.modeling -   Randomly initialize the top level classifiers!\n",
            "04/10/2021 12:16:34 - INFO - pytorch_pretrained_bert.modeling -   Failed for Randomly initialize the top level classifiers!\n",
            "04/10/2021 12:16:34 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForMultipleChoice_MT_general not initialized from pretrained model: ['classifiers.0.weight', 'classifiers.0.bias']\n",
            "04/10/2021 12:16:34 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForMultipleChoice_MT_general: ['classifier.0.weight', 'classifier.0.bias']\n",
            "04/10/2021 12:16:37 - INFO - __main__ -   Loading features from cached file data/dream/cached_train_tmp_64_dream\n",
            "04/10/2021 12:16:39 - INFO - __main__ -   ***** Running training *****\n",
            "04/10/2021 12:16:39 - INFO - __main__ -     Num Epochs = 8\n",
            "04/10/2021 12:16:39 - INFO - __main__ -     Instantaneous batch size per GPU = 8\n",
            "04/10/2021 12:16:39 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "04/10/2021 12:16:39 - INFO - __main__ -     Gradient Accumulation steps = 2\n",
            "04/10/2021 12:16:39 - INFO - __main__ -     Total optimization steps = 3056\n",
            "Epoch:   0% 0/8 [00:00<?, ?it/s]\n",
            "  0% 0/765 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Iteration:   0% 0/765 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.0:   0% 0/765 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.0:   0% 1/765 [00:00<11:50,  1.08it/s]\u001b[A\u001b[A\n",
            "  0% 1/765 [00:00<11:50,  1.08it/s]\u001b[A\n",
            "\n",
            "train loss: 0.03543504327535629:   0% 1/765 [00:00<11:50,  1.08it/s]\u001b[A\u001b[A/content/drive/My Drive/Colab Notebooks/MMM-MCQA-master/pytorch_pretrained_bert/optimization.py:273: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1005.)\n",
            "  next_m.mul_(beta1).add_(1 - beta1, grad)\n",
            "\n",
            "\n",
            "train loss: 0.03543504327535629:   0% 2/765 [00:02<12:49,  1.01s/it]\u001b[A\u001b[A\n",
            "  0% 2/765 [00:02<12:50,  1.01s/it]\u001b[A\n",
            "\n",
            "train loss: 0.05941923335194588:   0% 2/765 [00:02<12:49,  1.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.05941923335194588:   0% 3/765 [00:02<12:16,  1.03it/s]\u001b[A\u001b[A\n",
            "  0% 3/765 [00:02<12:17,  1.03it/s]\u001b[A\n",
            "\n",
            "train loss: 0.0930444523692131:   0% 3/765 [00:02<12:16,  1.03it/s] \u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.0930444523692131:   1% 4/765 [00:04<12:56,  1.02s/it]\u001b[A\u001b[A\n",
            "  1% 4/765 [00:04<12:57,  1.02s/it]\u001b[A\n",
            "\n",
            "train loss: 0.09409512020647526:   1% 4/765 [00:04<12:56,  1.02s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.09409512020647526:   1% 5/765 [00:05<12:24,  1.02it/s]\u001b[A\u001b[A\n",
            "  1% 5/765 [00:05<12:24,  1.02it/s]\u001b[A\n",
            "\n",
            "train loss: 0.13800496608018875:   1% 5/765 [00:05<12:24,  1.02it/s]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.13800496608018875:   1% 6/765 [00:06<13:01,  1.03s/it]\u001b[A\u001b[A\n",
            "  1% 6/765 [00:06<13:01,  1.03s/it]\u001b[A\n",
            "\n",
            "train loss: 0.13506708666682243:   1% 6/765 [00:06<13:01,  1.03s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.13506708666682243:   1% 7/765 [00:07<12:30,  1.01it/s]\u001b[A\u001b[A\n",
            "  1% 7/765 [00:07<12:30,  1.01it/s]\u001b[A\n",
            "\n",
            "train loss: 0.1349355929664203:   1% 7/765 [00:07<12:30,  1.01it/s] \u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.1349355929664203:   1% 8/765 [00:08<13:12,  1.05s/it]\u001b[A\u001b[A\n",
            "  1% 8/765 [00:08<13:12,  1.05s/it]\u001b[A\n",
            "\n",
            "train loss: 0.12355725513771176:   1% 8/765 [00:08<13:12,  1.05s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.12355725513771176:   1% 9/765 [00:09<12:35,  1.00it/s]\u001b[A\u001b[A\n",
            "  1% 9/765 [00:09<12:35,  1.00it/s]\u001b[A\n",
            "\n",
            "train loss: 0.1154369136525525:   1% 9/765 [00:09<12:35,  1.00it/s] \u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.1154369136525525:   1% 10/765 [00:10<13:12,  1.05s/it]\u001b[A\u001b[A\n",
            "  1% 10/765 [00:10<13:12,  1.05s/it]\u001b[A\n",
            "\n",
            "train loss: 0.11658239848911763:   1% 10/765 [00:10<13:12,  1.05s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.11658239848911763:   1% 11/765 [00:11<12:37,  1.01s/it]\u001b[A\u001b[A\n",
            "  1% 11/765 [00:11<12:37,  1.01s/it]\u001b[A\n",
            "\n",
            "train loss: 0.11102699894796718:   1% 11/765 [00:11<12:37,  1.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.11102699894796718:   2% 12/765 [00:12<13:14,  1.06s/it]\u001b[A\u001b[A\n",
            "  2% 12/765 [00:12<13:14,  1.06s/it]\u001b[A\n",
            "\n",
            "train loss: 0.11745691485702991:   2% 12/765 [00:12<13:14,  1.06s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.11745691485702991:   2% 13/765 [00:13<12:41,  1.01s/it]\u001b[A\u001b[A\n",
            "  2% 13/765 [00:13<12:41,  1.01s/it]\u001b[A\n",
            "\n",
            "train loss: 0.12333012830752593:   2% 13/765 [00:13<12:41,  1.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.12333012830752593:   2% 14/765 [00:14<13:10,  1.05s/it]\u001b[A\u001b[A\n",
            "  2% 14/765 [00:14<13:10,  1.05s/it]\u001b[A\n",
            "\n",
            "train loss: 0.11773100442120008:   2% 14/765 [00:14<13:10,  1.05s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.11773100442120008:   2% 15/765 [00:15<12:31,  1.00s/it]\u001b[A\u001b[A\n",
            "  2% 15/765 [00:15<12:31,  1.00s/it]\u001b[A\n",
            "\n",
            "train loss: 0.11727189670006434:   2% 15/765 [00:15<12:31,  1.00s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.11727189670006434:   2% 16/765 [00:16<13:12,  1.06s/it]\u001b[A\u001b[A\n",
            "  2% 16/765 [00:16<13:12,  1.06s/it]\u001b[A\n",
            "\n",
            "train loss: 0.11279936577193439:   2% 16/765 [00:16<13:12,  1.06s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.11279936577193439:   2% 17/765 [00:17<12:33,  1.01s/it]\u001b[A\u001b[A\n",
            "  2% 17/765 [00:17<12:33,  1.01s/it]\u001b[A\n",
            "\n",
            "train loss: 0.11543499262017362:   2% 17/765 [00:17<12:33,  1.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.11543499262017362:   2% 18/765 [00:18<13:07,  1.05s/it]\u001b[A\u001b[A\n",
            "  2% 18/765 [00:18<13:07,  1.05s/it]\u001b[A\n",
            "\n",
            "train loss: 0.11286154658430153:   2% 18/765 [00:18<13:07,  1.05s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.11286154658430153:   2% 19/765 [00:19<12:37,  1.02s/it]\u001b[A\u001b[A\n",
            "  2% 19/765 [00:19<12:37,  1.02s/it]\u001b[A\n",
            "\n",
            "train loss: 0.11015140500507857:   2% 19/765 [00:19<12:37,  1.02s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.11015140500507857:   3% 20/765 [00:20<13:08,  1.06s/it]\u001b[A\u001b[A\n",
            "  3% 20/765 [00:20<13:08,  1.06s/it]\u001b[A\n",
            "\n",
            "train loss: 0.10785546861588954:   3% 20/765 [00:20<13:08,  1.06s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.10785546861588954:   3% 21/765 [00:21<12:38,  1.02s/it]\u001b[A\u001b[A\n",
            "  3% 21/765 [00:21<12:38,  1.02s/it]\u001b[A\n",
            "\n",
            "train loss: 0.10505054820151556:   3% 21/765 [00:21<12:38,  1.02s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.10505054820151556:   3% 22/765 [00:22<13:17,  1.07s/it]\u001b[A\u001b[A\n",
            "  3% 22/765 [00:22<13:17,  1.07s/it]\u001b[A\n",
            "\n",
            "train loss: 0.10430363667282191:   3% 22/765 [00:22<13:17,  1.07s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.10430363667282191:   3% 23/765 [00:23<12:45,  1.03s/it]\u001b[A\u001b[A\n",
            "  3% 23/765 [00:23<12:45,  1.03s/it]\u001b[A\n",
            "\n",
            "train loss: 0.10256342719430508:   3% 23/765 [00:23<12:45,  1.03s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.10256342719430508:   3% 24/765 [00:24<13:19,  1.08s/it]\u001b[A\u001b[A\n",
            "  3% 24/765 [00:24<13:19,  1.08s/it]\u001b[A\n",
            "\n",
            "train loss: 0.10370174547036488:   3% 24/765 [00:24<13:19,  1.08s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.10370174547036488:   3% 25/765 [00:25<12:44,  1.03s/it]\u001b[A\u001b[A\n",
            "  3% 25/765 [00:25<12:44,  1.03s/it]\u001b[A\n",
            "\n",
            "train loss: 0.10367109894752502:   3% 25/765 [00:25<12:44,  1.03s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.10367109894752502:   3% 26/765 [00:27<13:21,  1.09s/it]\u001b[A\u001b[A\n",
            "  3% 26/765 [00:27<13:21,  1.09s/it]\u001b[A\n",
            "\n",
            "train loss: 0.09992747778932635:   3% 26/765 [00:27<13:21,  1.09s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.09992747778932635:   4% 27/765 [00:27<12:45,  1.04s/it]\u001b[A\u001b[A\n",
            "  4% 27/765 [00:27<12:45,  1.04s/it]\u001b[A\n",
            "\n",
            "train loss: 0.10178646083093351:   4% 27/765 [00:27<12:45,  1.04s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.10178646083093351:   4% 28/765 [00:29<13:23,  1.09s/it]\u001b[A\u001b[A\n",
            "  4% 28/765 [00:29<13:23,  1.09s/it]\u001b[A\n",
            "\n",
            "train loss: 0.10205687073591564:   4% 28/765 [00:29<13:23,  1.09s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.10205687073591564:   4% 29/765 [00:30<12:46,  1.04s/it]\u001b[A\u001b[A\n",
            "  4% 29/765 [00:30<12:46,  1.04s/it]\u001b[A\n",
            "\n",
            "train loss: 0.10086475026890121:   4% 29/765 [00:30<12:46,  1.04s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.10086475026890121:   4% 30/765 [00:31<13:17,  1.09s/it]\u001b[A\u001b[A\n",
            "  4% 30/765 [00:31<13:17,  1.09s/it]\u001b[A\n",
            "\n",
            "train loss: 0.10093923232828578:   4% 30/765 [00:31<13:17,  1.09s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.10093923232828578:   4% 31/765 [00:32<12:47,  1.05s/it]\u001b[A\u001b[A\n",
            "  4% 31/765 [00:32<12:47,  1.05s/it]\u001b[A\n",
            "\n",
            "train loss: 0.0996282724062762:   4% 31/765 [00:32<12:47,  1.05s/it] \u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.0996282724062762:   4% 32/765 [00:33<13:19,  1.09s/it]\u001b[A\u001b[A\n",
            "  4% 32/765 [00:33<13:19,  1.09s/it]\u001b[A\n",
            "\n",
            "train loss: 0.09988627707934938:   4% 32/765 [00:33<13:19,  1.09s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.09988627707934938:   4% 33/765 [00:34<12:48,  1.05s/it]\u001b[A\u001b[A\n",
            "  4% 33/765 [00:34<12:48,  1.05s/it]\u001b[A\n",
            "\n",
            "train loss: 0.09973013070835308:   4% 33/765 [00:34<12:48,  1.05s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.09973013070835308:   4% 34/765 [00:35<13:21,  1.10s/it]\u001b[A\u001b[A\n",
            "  4% 34/765 [00:35<13:21,  1.10s/it]\u001b[A\n",
            "\n",
            "train loss: 0.1011354211882195:   4% 34/765 [00:35<13:21,  1.10s/it] \u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.1011354211882195:   5% 35/765 [00:36<12:48,  1.05s/it]\u001b[A\u001b[A\n",
            "  5% 35/765 [00:36<12:48,  1.05s/it]\u001b[A\n",
            "\n",
            "train loss: 0.10034908042954548:   5% 35/765 [00:36<12:48,  1.05s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.10034908042954548:   5% 36/765 [00:37<13:20,  1.10s/it]\u001b[A\u001b[A\n",
            "  5% 36/765 [00:37<13:20,  1.10s/it]\u001b[A\n",
            "\n",
            "train loss: 0.09967433192974164:   5% 36/765 [00:37<13:20,  1.10s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.09967433192974164:   5% 37/765 [00:38<12:45,  1.05s/it]\u001b[A\u001b[A\n",
            "  5% 37/765 [00:38<12:45,  1.05s/it]\u001b[A\n",
            "\n",
            "train loss: 0.09893542334336687:   5% 37/765 [00:38<12:45,  1.05s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.09893542334336687:   5% 38/765 [00:39<13:19,  1.10s/it]\u001b[A\u001b[A\n",
            "  5% 38/765 [00:39<13:19,  1.10s/it]\u001b[A\n",
            "\n",
            "train loss: 0.09731242911105878:   5% 38/765 [00:39<13:19,  1.10s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.09731242911105878:   5% 39/765 [00:40<12:46,  1.06s/it]\u001b[A\u001b[A\n",
            "  5% 39/765 [00:40<12:46,  1.06s/it]\u001b[A\n",
            "\n",
            "train loss: 0.09593786889066298:   5% 39/765 [00:40<12:46,  1.06s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.09593786889066298:   5% 40/765 [00:42<13:22,  1.11s/it]\u001b[A\u001b[A\n",
            "  5% 40/765 [00:42<13:22,  1.11s/it]\u001b[A\n",
            "\n",
            "train loss: 0.09562604071106762:   5% 40/765 [00:42<13:22,  1.11s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.09562604071106762:   5% 41/765 [00:43<12:53,  1.07s/it]\u001b[A\u001b[A\n",
            "  5% 41/765 [00:43<12:53,  1.07s/it]\u001b[A\n",
            "\n",
            "train loss: 0.09430105155106724:   5% 41/765 [00:43<12:53,  1.07s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.09430105155106724:   5% 42/765 [00:44<13:26,  1.12s/it]\u001b[A\u001b[A\n",
            "  5% 42/765 [00:44<13:26,  1.12s/it]\u001b[A\n",
            "\n",
            "train loss: 0.09349487373782765:   5% 42/765 [00:44<13:26,  1.12s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.09349487373782765:   6% 43/765 [00:45<12:54,  1.07s/it]\u001b[A\u001b[A\n",
            "  6% 43/765 [00:45<12:54,  1.07s/it]\u001b[A\n",
            "\n",
            "train loss: 0.09287034778660813:   6% 43/765 [00:45<12:54,  1.07s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.09287034778660813:   6% 44/765 [00:46<13:25,  1.12s/it]\u001b[A\u001b[A\n",
            "  6% 44/765 [00:46<13:25,  1.12s/it]\u001b[A\n",
            "\n",
            "train loss: 0.09166519316336648:   6% 44/765 [00:46<13:25,  1.12s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.09166519316336648:   6% 45/765 [00:47<12:55,  1.08s/it]\u001b[A\u001b[A\n",
            "  6% 45/765 [00:47<12:55,  1.08s/it]\u001b[A\n",
            "\n",
            "train loss: 0.09120280881308847:   6% 45/765 [00:47<12:55,  1.08s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.09120280881308847:   6% 46/765 [00:48<13:29,  1.13s/it]\u001b[A\u001b[A\n",
            "  6% 46/765 [00:48<13:29,  1.13s/it]\u001b[A\n",
            "\n",
            "train loss: 0.09043396165108551:   6% 46/765 [00:48<13:29,  1.13s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.09043396165108551:   6% 47/765 [00:49<13:01,  1.09s/it]\u001b[A\u001b[A\n",
            "  6% 47/765 [00:49<13:01,  1.09s/it]\u001b[A\n",
            "\n",
            "train loss: 0.09057216597919135:   6% 47/765 [00:49<13:01,  1.09s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.09057216597919135:   6% 48/765 [00:50<13:35,  1.14s/it]\u001b[A\u001b[A\n",
            "  6% 48/765 [00:50<13:35,  1.14s/it]\u001b[A\n",
            "\n",
            "train loss: 0.08972315286519006:   6% 48/765 [00:50<13:35,  1.14s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.08972315286519006:   6% 49/765 [00:51<13:07,  1.10s/it]\u001b[A\u001b[A\n",
            "  6% 49/765 [00:51<13:07,  1.10s/it]\u001b[A\n",
            "\n",
            "train loss: 0.08920730846192763:   6% 49/765 [00:51<13:07,  1.10s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.08920730846192763:   7% 50/765 [00:53<13:39,  1.15s/it]\u001b[A\u001b[A\n",
            "  7% 50/765 [00:53<13:39,  1.15s/it]\u001b[A\n",
            "\n",
            "train loss: 0.08805146617814899:   7% 50/765 [00:53<13:39,  1.15s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.08805146617814899:   7% 51/765 [00:54<13:10,  1.11s/it]\u001b[A\u001b[A\n",
            "  7% 51/765 [00:54<13:10,  1.11s/it]\u001b[A\n",
            "\n",
            "train loss: 0.08800339346349824:   7% 51/765 [00:54<13:10,  1.11s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.08800339346349824:   7% 52/765 [00:55<13:43,  1.15s/it]\u001b[A\u001b[A\n",
            "  7% 52/765 [00:55<13:43,  1.15s/it]\u001b[A\n",
            "\n",
            "train loss: 0.08758164868833354:   7% 52/765 [00:55<13:43,  1.15s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.08758164868833354:   7% 53/765 [00:56<13:14,  1.12s/it]\u001b[A\u001b[A\n",
            "  7% 53/765 [00:56<13:14,  1.12s/it]\u001b[A\n",
            "\n",
            "train loss: 0.0873235448456879:   7% 53/765 [00:56<13:14,  1.12s/it] \u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.0873235448456879:   7% 54/765 [00:57<13:47,  1.16s/it]\u001b[A\u001b[A\n",
            "  7% 54/765 [00:57<13:47,  1.16s/it]\u001b[A\n",
            "\n",
            "train loss: 0.08685891307821428:   7% 54/765 [00:57<13:47,  1.16s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.08685891307821428:   7% 55/765 [00:58<13:16,  1.12s/it]\u001b[A\u001b[A\n",
            "  7% 55/765 [00:58<13:16,  1.12s/it]\u001b[A\n",
            "\n",
            "train loss: 0.08667089321057905:   7% 55/765 [00:58<13:16,  1.12s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.08667089321057905:   7% 56/765 [01:00<13:47,  1.17s/it]\u001b[A\u001b[A\n",
            "  7% 56/765 [01:00<13:47,  1.17s/it]\u001b[A\n",
            "\n",
            "train loss: 0.0860302303086168:   7% 56/765 [01:00<13:47,  1.17s/it] \u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.0860302303086168:   7% 57/765 [01:01<13:19,  1.13s/it]\u001b[A\u001b[A\n",
            "  7% 57/765 [01:01<13:19,  1.13s/it]\u001b[A\n",
            "\n",
            "train loss: 0.08533563633171613:   7% 57/765 [01:01<13:19,  1.13s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.08533563633171613:   8% 58/765 [01:02<13:49,  1.17s/it]\u001b[A\u001b[A\n",
            "  8% 58/765 [01:02<13:49,  1.17s/it]\u001b[A\n",
            "\n",
            "train loss: 0.08502081908478305:   8% 58/765 [01:02<13:49,  1.17s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.08502081908478305:   8% 59/765 [01:03<13:21,  1.13s/it]\u001b[A\u001b[A\n",
            "  8% 59/765 [01:03<13:21,  1.13s/it]\u001b[A\n",
            "\n",
            "train loss: 0.085203221778117:   8% 59/765 [01:03<13:21,  1.13s/it]  \u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.085203221778117:   8% 60/765 [01:04<13:54,  1.18s/it]\u001b[A\u001b[A\n",
            "  8% 60/765 [01:04<13:54,  1.18s/it]\u001b[A\n",
            "\n",
            "train loss: 0.08485005471544961:   8% 60/765 [01:04<13:54,  1.18s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.08485005471544961:   8% 61/765 [01:05<13:28,  1.15s/it]\u001b[A\u001b[A\n",
            "  8% 61/765 [01:05<13:28,  1.15s/it]\u001b[A\n",
            "\n",
            "train loss: 0.08465660374123053:   8% 61/765 [01:05<13:28,  1.15s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.08465660374123053:   8% 62/765 [01:07<13:56,  1.19s/it]\u001b[A\u001b[A\n",
            "  8% 62/765 [01:07<13:56,  1.19s/it]\u001b[A\n",
            "\n",
            "train loss: 0.08422744873490545:   8% 62/765 [01:07<13:56,  1.19s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.08422744873490545:   8% 63/765 [01:08<13:25,  1.15s/it]\u001b[A\u001b[A\n",
            "  8% 63/765 [01:08<13:25,  1.15s/it]\u001b[A\n",
            "\n",
            "train loss: 0.08415092372645934:   8% 63/765 [01:08<13:25,  1.15s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.08415092372645934:   8% 64/765 [01:09<13:56,  1.19s/it]\u001b[A\u001b[A\n",
            "  8% 64/765 [01:09<13:56,  1.19s/it]\u001b[A\n",
            "\n",
            "train loss: 0.08391104101610836:   8% 64/765 [01:09<13:56,  1.19s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.08391104101610836:   8% 65/765 [01:10<13:24,  1.15s/it]\u001b[A\u001b[A\n",
            "  8% 65/765 [01:10<13:24,  1.15s/it]\u001b[A\n",
            "\n",
            "train loss: 0.08340932794201833:   8% 65/765 [01:10<13:24,  1.15s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.08340932794201833:   9% 66/765 [01:11<13:52,  1.19s/it]\u001b[A\u001b[A\n",
            "  9% 66/765 [01:11<13:52,  1.19s/it]\u001b[A\n",
            "\n",
            "train loss: 0.08298082975670695:   9% 66/765 [01:11<13:52,  1.19s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.08298082975670695:   9% 67/765 [01:12<13:20,  1.15s/it]\u001b[A\u001b[A\n",
            "  9% 67/765 [01:12<13:20,  1.15s/it]\u001b[A\n",
            "\n",
            "train loss: 0.08249007508770298:   9% 67/765 [01:12<13:20,  1.15s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.08249007508770298:   9% 68/765 [01:14<13:47,  1.19s/it]\u001b[A\u001b[A\n",
            "  9% 68/765 [01:14<13:47,  1.19s/it]\u001b[A\n",
            "\n",
            "train loss: 0.08231467083918259:   9% 68/765 [01:14<13:47,  1.19s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.08231467083918259:   9% 69/765 [01:15<13:15,  1.14s/it]\u001b[A\u001b[A\n",
            "  9% 69/765 [01:15<13:15,  1.14s/it]\u001b[A\n",
            "\n",
            "train loss: 0.08170707608856585:   9% 69/765 [01:15<13:15,  1.14s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.08170707608856585:   9% 70/765 [01:16<13:39,  1.18s/it]\u001b[A\u001b[A\n",
            "  9% 70/765 [01:16<13:39,  1.18s/it]\u001b[A\n",
            "\n",
            "train loss: 0.08169521890314561:   9% 70/765 [01:16<13:39,  1.18s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.08169521890314561:   9% 71/765 [01:17<13:05,  1.13s/it]\u001b[A\u001b[A\n",
            "  9% 71/765 [01:17<13:05,  1.13s/it]\u001b[A\n",
            "\n",
            "train loss: 0.08135975791062687:   9% 71/765 [01:17<13:05,  1.13s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.08135975791062687:   9% 72/765 [01:18<13:33,  1.17s/it]\u001b[A\u001b[A\n",
            "  9% 72/765 [01:18<13:33,  1.17s/it]\u001b[A\n",
            "\n",
            "train loss: 0.081032866340441:   9% 72/765 [01:18<13:33,  1.17s/it]  \u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.081032866340441:  10% 73/765 [01:19<12:59,  1.13s/it]\u001b[A\u001b[A\n",
            " 10% 73/765 [01:19<12:59,  1.13s/it]\u001b[A\n",
            "\n",
            "train loss: 0.0804046912322918:  10% 73/765 [01:19<12:59,  1.13s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.0804046912322918:  10% 74/765 [01:21<13:31,  1.17s/it]\u001b[A\u001b[A\n",
            " 10% 74/765 [01:21<13:31,  1.17s/it]\u001b[A\n",
            "\n",
            "train loss: 0.08030055547636505:  10% 74/765 [01:21<13:31,  1.17s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.08030055547636505:  10% 75/765 [01:22<12:55,  1.12s/it]\u001b[A\u001b[A\n",
            " 10% 75/765 [01:22<12:55,  1.12s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07987834059943756:  10% 75/765 [01:22<12:55,  1.12s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07987834059943756:  10% 76/765 [01:23<13:20,  1.16s/it]\u001b[A\u001b[A\n",
            " 10% 76/765 [01:23<13:20,  1.16s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07979535060248484:  10% 76/765 [01:23<13:20,  1.16s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07979535060248484:  10% 77/765 [01:24<12:47,  1.12s/it]\u001b[A\u001b[A\n",
            " 10% 77/765 [01:24<12:47,  1.12s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07967503430539524:  10% 77/765 [01:24<12:47,  1.12s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07967503430539524:  10% 78/765 [01:25<13:14,  1.16s/it]\u001b[A\u001b[A\n",
            " 10% 78/765 [01:25<13:14,  1.16s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07965626542528088:  10% 78/765 [01:25<13:14,  1.16s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07965626542528088:  10% 79/765 [01:26<12:43,  1.11s/it]\u001b[A\u001b[A\n",
            " 10% 79/765 [01:26<12:43,  1.11s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07932174105574435:  10% 79/765 [01:26<12:43,  1.11s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07932174105574435:  10% 80/765 [01:27<13:15,  1.16s/it]\u001b[A\u001b[A\n",
            " 10% 80/765 [01:27<13:16,  1.16s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07925060515990481:  10% 80/765 [01:27<13:15,  1.16s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07925060515990481:  11% 81/765 [01:28<12:44,  1.12s/it]\u001b[A\u001b[A\n",
            " 11% 81/765 [01:28<12:44,  1.12s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07919233498152023:  11% 81/765 [01:28<12:44,  1.12s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07919233498152023:  11% 82/765 [01:30<13:07,  1.15s/it]\u001b[A\u001b[A\n",
            " 11% 82/765 [01:30<13:07,  1.15s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07915725816813547:  11% 82/765 [01:30<13:07,  1.15s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07915725816813547:  11% 83/765 [01:31<12:30,  1.10s/it]\u001b[A\u001b[A\n",
            " 11% 83/765 [01:31<12:30,  1.10s/it]\u001b[A\n",
            "\n",
            "train loss: 0.0789923586557249:  11% 83/765 [01:31<12:30,  1.10s/it] \u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.0789923586557249:  11% 84/765 [01:32<12:56,  1.14s/it]\u001b[A\u001b[A\n",
            " 11% 84/765 [01:32<12:56,  1.14s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07871474896646327:  11% 84/765 [01:32<12:56,  1.14s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07871474896646327:  11% 85/765 [01:33<12:21,  1.09s/it]\u001b[A\u001b[A\n",
            " 11% 85/765 [01:33<12:21,  1.09s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07848769666298347:  11% 85/765 [01:33<12:21,  1.09s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07848769666298347:  11% 86/765 [01:34<12:52,  1.14s/it]\u001b[A\u001b[A\n",
            " 11% 86/765 [01:34<12:52,  1.14s/it]\u001b[A\n",
            "\n",
            "train loss: 0.0783585014016649:  11% 86/765 [01:34<12:52,  1.14s/it] \u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.0783585014016649:  11% 87/765 [01:35<12:21,  1.09s/it]\u001b[A\u001b[A\n",
            " 11% 87/765 [01:35<12:21,  1.09s/it]\u001b[A\n",
            "\n",
            "train loss: 0.0781552938359051:  11% 87/765 [01:35<12:21,  1.09s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.0781552938359051:  12% 88/765 [01:36<12:46,  1.13s/it]\u001b[A\u001b[A\n",
            " 12% 88/765 [01:36<12:46,  1.13s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07795793841465969:  12% 88/765 [01:36<12:46,  1.13s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07795793841465969:  12% 89/765 [01:37<12:12,  1.08s/it]\u001b[A\u001b[A\n",
            " 12% 89/765 [01:37<12:12,  1.08s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07785982252464871:  12% 89/765 [01:37<12:12,  1.08s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07785982252464871:  12% 90/765 [01:38<12:40,  1.13s/it]\u001b[A\u001b[A\n",
            " 12% 90/765 [01:38<12:40,  1.13s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07773269289690588:  12% 90/765 [01:38<12:40,  1.13s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07773269289690588:  12% 91/765 [01:39<12:08,  1.08s/it]\u001b[A\u001b[A\n",
            " 12% 91/765 [01:39<12:08,  1.08s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07761242927389812:  12% 91/765 [01:39<12:08,  1.08s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07761242927389812:  12% 92/765 [01:41<12:35,  1.12s/it]\u001b[A\u001b[A\n",
            " 12% 92/765 [01:41<12:35,  1.12s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07734988474934969:  12% 92/765 [01:41<12:35,  1.12s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07734988474934969:  12% 93/765 [01:42<12:05,  1.08s/it]\u001b[A\u001b[A\n",
            " 12% 93/765 [01:42<12:05,  1.08s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07715451111516325:  12% 93/765 [01:42<12:05,  1.08s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07715451111516325:  12% 94/765 [01:43<12:34,  1.12s/it]\u001b[A\u001b[A\n",
            " 12% 94/765 [01:43<12:34,  1.12s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07699237655887896:  12% 94/765 [01:43<12:34,  1.12s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07699237655887896:  12% 95/765 [01:44<12:00,  1.08s/it]\u001b[A\u001b[A\n",
            " 12% 95/765 [01:44<12:00,  1.08s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07693875183988559:  12% 95/765 [01:44<12:00,  1.08s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07693875183988559:  13% 96/765 [01:45<12:31,  1.12s/it]\u001b[A\u001b[A\n",
            " 13% 96/765 [01:45<12:31,  1.12s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07676128584231871:  13% 96/765 [01:45<12:31,  1.12s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07676128584231871:  13% 97/765 [01:46<12:00,  1.08s/it]\u001b[A\u001b[A\n",
            " 13% 97/765 [01:46<12:00,  1.08s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07656039392633229:  13% 97/765 [01:46<12:00,  1.08s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07656039392633229:  13% 98/765 [01:47<12:28,  1.12s/it]\u001b[A\u001b[A\n",
            " 13% 98/765 [01:47<12:28,  1.12s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07638866666286272:  13% 98/765 [01:47<12:28,  1.12s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07638866666286272:  13% 99/765 [01:48<11:59,  1.08s/it]\u001b[A\u001b[A\n",
            " 13% 99/765 [01:48<11:59,  1.08s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07641192396745236:  13% 99/765 [01:48<11:59,  1.08s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07641192396745236:  13% 100/765 [01:49<12:26,  1.12s/it]\u001b[A\u001b[A\n",
            " 13% 100/765 [01:49<12:26,  1.12s/it]\u001b[A\n",
            "\n",
            "train loss: 0.0762734970357269:  13% 100/765 [01:49<12:26,  1.12s/it] \u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.0762734970357269:  13% 101/765 [01:50<11:57,  1.08s/it]\u001b[A\u001b[A\n",
            " 13% 101/765 [01:50<11:57,  1.08s/it]\u001b[A\n",
            "\n",
            "train loss: 0.0763377666676251:  13% 101/765 [01:50<11:57,  1.08s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.0763377666676251:  13% 102/765 [01:52<12:24,  1.12s/it]\u001b[A\u001b[A\n",
            " 13% 102/765 [01:52<12:24,  1.12s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07619138177959066:  13% 102/765 [01:52<12:24,  1.12s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07619138177959066:  13% 103/765 [01:53<11:54,  1.08s/it]\u001b[A\u001b[A\n",
            " 13% 103/765 [01:53<11:54,  1.08s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07597556702105455:  13% 103/765 [01:53<11:54,  1.08s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07597556702105455:  14% 104/765 [01:54<12:20,  1.12s/it]\u001b[A\u001b[A\n",
            " 14% 104/765 [01:54<12:20,  1.12s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07571010548585597:  14% 104/765 [01:54<12:20,  1.12s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07571010548585597:  14% 105/765 [01:55<11:51,  1.08s/it]\u001b[A\u001b[A\n",
            " 14% 105/765 [01:55<11:51,  1.08s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07545632343029691:  14% 105/765 [01:55<11:51,  1.08s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07545632343029691:  14% 106/765 [01:56<12:23,  1.13s/it]\u001b[A\u001b[A\n",
            " 14% 106/765 [01:56<12:23,  1.13s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07532398718110514:  14% 106/765 [01:56<12:23,  1.13s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07532398718110514:  14% 107/765 [01:57<11:52,  1.08s/it]\u001b[A\u001b[A\n",
            " 14% 107/765 [01:57<11:52,  1.08s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07499764757840155:  14% 107/765 [01:57<11:52,  1.08s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07499764757840155:  14% 108/765 [01:58<12:19,  1.13s/it]\u001b[A\u001b[A\n",
            " 14% 108/765 [01:58<12:19,  1.13s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07489930951312461:  14% 108/765 [01:58<12:19,  1.13s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07489930951312461:  14% 109/765 [01:59<11:52,  1.09s/it]\u001b[A\u001b[A\n",
            " 14% 109/765 [01:59<11:52,  1.09s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07463532411963295:  14% 109/765 [01:59<11:52,  1.09s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07463532411963295:  14% 110/765 [02:00<12:22,  1.13s/it]\u001b[A\u001b[A\n",
            " 14% 110/765 [02:00<12:22,  1.13s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07432276209477674:  14% 110/765 [02:00<12:22,  1.13s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07432276209477674:  15% 111/765 [02:01<11:53,  1.09s/it]\u001b[A\u001b[A\n",
            " 15% 111/765 [02:01<11:53,  1.09s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07404333694527547:  15% 111/765 [02:01<11:53,  1.09s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07404333694527547:  15% 112/765 [02:03<12:18,  1.13s/it]\u001b[A\u001b[A\n",
            " 15% 112/765 [02:03<12:18,  1.13s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07381591984968898:  15% 112/765 [02:03<12:18,  1.13s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07381591984968898:  15% 113/765 [02:04<11:47,  1.09s/it]\u001b[A\u001b[A\n",
            " 15% 113/765 [02:04<11:47,  1.09s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07349665442366252:  15% 113/765 [02:04<11:47,  1.09s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07349665442366252:  15% 114/765 [02:05<12:16,  1.13s/it]\u001b[A\u001b[A\n",
            " 15% 114/765 [02:05<12:16,  1.13s/it]\u001b[A\n",
            "\n",
            "train loss: 0.0732542552756505:  15% 114/765 [02:05<12:16,  1.13s/it] \u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.0732542552756505:  15% 115/765 [02:06<11:48,  1.09s/it]\u001b[A\u001b[A\n",
            " 15% 115/765 [02:06<11:48,  1.09s/it]\u001b[A\n",
            "\n",
            "train loss: 0.0730203222564381:  15% 115/765 [02:06<11:48,  1.09s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.0730203222564381:  15% 116/765 [02:07<12:15,  1.13s/it]\u001b[A\u001b[A\n",
            " 15% 116/765 [02:07<12:15,  1.13s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07307634569287043:  15% 116/765 [02:07<12:15,  1.13s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07307634569287043:  15% 117/765 [02:08<11:46,  1.09s/it]\u001b[A\u001b[A\n",
            " 15% 117/765 [02:08<11:46,  1.09s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07292833681512847:  15% 117/765 [02:08<11:46,  1.09s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07292833681512847:  15% 118/765 [02:09<12:15,  1.14s/it]\u001b[A\u001b[A\n",
            " 15% 118/765 [02:09<12:15,  1.14s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07263697869286447:  15% 118/765 [02:09<12:15,  1.14s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07263697869286447:  16% 119/765 [02:10<11:46,  1.09s/it]\u001b[A\u001b[A\n",
            " 16% 119/765 [02:10<11:46,  1.09s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07236301212595041:  16% 119/765 [02:10<11:46,  1.09s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07236301212595041:  16% 120/765 [02:12<12:15,  1.14s/it]\u001b[A\u001b[A\n",
            " 16% 120/765 [02:12<12:15,  1.14s/it]\u001b[A\n",
            "\n",
            "train loss: 0.0721046887881433:  16% 120/765 [02:12<12:15,  1.14s/it] \u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.0721046887881433:  16% 121/765 [02:13<11:44,  1.09s/it]\u001b[A\u001b[A\n",
            " 16% 121/765 [02:13<11:44,  1.09s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07218960123829359:  16% 121/765 [02:13<11:44,  1.09s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07218960123829359:  16% 122/765 [02:14<12:11,  1.14s/it]\u001b[A\u001b[A\n",
            " 16% 122/765 [02:14<12:11,  1.14s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07184941629253205:  16% 122/765 [02:14<12:11,  1.14s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07184941629253205:  16% 123/765 [02:15<11:44,  1.10s/it]\u001b[A\u001b[A\n",
            " 16% 123/765 [02:15<11:44,  1.10s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07173342550763996:  16% 123/765 [02:15<11:44,  1.10s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07173342550763996:  16% 124/765 [02:16<12:13,  1.14s/it]\u001b[A\u001b[A\n",
            " 16% 124/765 [02:16<12:13,  1.14s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07156037992136853:  16% 124/765 [02:16<12:13,  1.14s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07156037992136853:  16% 125/765 [02:17<11:44,  1.10s/it]\u001b[A\u001b[A\n",
            " 16% 125/765 [02:17<11:44,  1.10s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07148441102355718:  16% 125/765 [02:17<11:44,  1.10s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07148441102355718:  16% 126/765 [02:18<12:18,  1.16s/it]\u001b[A\u001b[A\n",
            " 16% 126/765 [02:18<12:18,  1.16s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07163378551218008:  16% 126/765 [02:18<12:18,  1.16s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07163378551218008:  17% 127/765 [02:19<11:47,  1.11s/it]\u001b[A\u001b[A\n",
            " 17% 127/765 [02:19<11:47,  1.11s/it]\u001b[A\n",
            "\n",
            "train loss: 0.0714408626163921:  17% 127/765 [02:19<11:47,  1.11s/it] \u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.0714408626163921:  17% 128/765 [02:21<12:14,  1.15s/it]\u001b[A\u001b[A\n",
            " 17% 128/765 [02:21<12:14,  1.15s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07140706158679677:  17% 128/765 [02:21<12:14,  1.15s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07140706158679677:  17% 129/765 [02:22<11:45,  1.11s/it]\u001b[A\u001b[A\n",
            " 17% 129/765 [02:22<11:45,  1.11s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07141741023709376:  17% 129/765 [02:22<11:45,  1.11s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07141741023709376:  17% 130/765 [02:23<12:09,  1.15s/it]\u001b[A\u001b[A\n",
            " 17% 130/765 [02:23<12:09,  1.15s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07134085632144259:  17% 130/765 [02:23<12:09,  1.15s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07134085632144259:  17% 131/765 [02:24<11:40,  1.11s/it]\u001b[A\u001b[A\n",
            " 17% 131/765 [02:24<11:40,  1.11s/it]\u001b[A\n",
            "\n",
            "train loss: 0.0713057229295373:  17% 131/765 [02:24<11:40,  1.11s/it] \u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.0713057229295373:  17% 132/765 [02:25<12:07,  1.15s/it]\u001b[A\u001b[A\n",
            " 17% 132/765 [02:25<12:07,  1.15s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07123796415345912:  17% 132/765 [02:25<12:07,  1.15s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07123796415345912:  17% 133/765 [02:26<11:40,  1.11s/it]\u001b[A\u001b[A\n",
            " 17% 133/765 [02:26<11:40,  1.11s/it]\u001b[A\n",
            "\n",
            "train loss: 0.0711693447713453:  17% 133/765 [02:26<11:40,  1.11s/it] \u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.0711693447713453:  18% 134/765 [02:27<12:08,  1.16s/it]\u001b[A\u001b[A\n",
            " 18% 134/765 [02:27<12:08,  1.16s/it]\u001b[A\n",
            "\n",
            "train loss: 0.0710476478353254:  18% 134/765 [02:27<12:08,  1.16s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.0710476478353254:  18% 135/765 [02:28<11:40,  1.11s/it]\u001b[A\u001b[A\n",
            " 18% 135/765 [02:28<11:40,  1.11s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07102068932382045:  18% 135/765 [02:28<11:40,  1.11s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07102068932382045:  18% 136/765 [02:30<12:06,  1.16s/it]\u001b[A\u001b[A\n",
            " 18% 136/765 [02:30<12:06,  1.16s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07081379097037237:  18% 136/765 [02:30<12:06,  1.16s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07081379097037237:  18% 137/765 [02:31<11:38,  1.11s/it]\u001b[A\u001b[A\n",
            " 18% 137/765 [02:31<11:38,  1.11s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07074921267501412:  18% 137/765 [02:31<11:38,  1.11s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07074921267501412:  18% 138/765 [02:32<12:08,  1.16s/it]\u001b[A\u001b[A\n",
            " 18% 138/765 [02:32<12:08,  1.16s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07051131231170418:  18% 138/765 [02:32<12:08,  1.16s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07051131231170418:  18% 139/765 [02:33<11:39,  1.12s/it]\u001b[A\u001b[A\n",
            " 18% 139/765 [02:33<11:39,  1.12s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07059571028372152:  18% 139/765 [02:33<11:39,  1.12s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07059571028372152:  18% 140/765 [02:34<12:06,  1.16s/it]\u001b[A\u001b[A\n",
            " 18% 140/765 [02:34<12:06,  1.16s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07066582392768136:  18% 140/765 [02:34<12:06,  1.16s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07066582392768136:  18% 141/765 [02:35<11:35,  1.12s/it]\u001b[A\u001b[A\n",
            " 18% 141/765 [02:35<11:35,  1.12s/it]\u001b[A\n",
            "\n",
            "train loss: 0.0704252094175693:  18% 141/765 [02:35<11:35,  1.12s/it] \u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.0704252094175693:  19% 142/765 [02:37<11:59,  1.16s/it]\u001b[A\u001b[A\n",
            " 19% 142/765 [02:37<11:59,  1.16s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07012880903760522:  19% 142/765 [02:37<11:59,  1.16s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07012880903760522:  19% 143/765 [02:38<11:28,  1.11s/it]\u001b[A\u001b[A\n",
            " 19% 143/765 [02:38<11:28,  1.11s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07007562838677135:  19% 143/765 [02:38<11:28,  1.11s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07007562838677135:  19% 144/765 [02:39<11:55,  1.15s/it]\u001b[A\u001b[A\n",
            " 19% 144/765 [02:39<11:55,  1.15s/it]\u001b[A\n",
            "\n",
            "train loss: 0.0700506562845678:  19% 144/765 [02:39<11:55,  1.15s/it] \u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.0700506562845678:  19% 145/765 [02:40<11:26,  1.11s/it]\u001b[A\u001b[A\n",
            " 19% 145/765 [02:40<11:26,  1.11s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07023466764467544:  19% 145/765 [02:40<11:26,  1.11s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07023466764467544:  19% 146/765 [02:41<11:51,  1.15s/it]\u001b[A\u001b[A\n",
            " 19% 146/765 [02:41<11:51,  1.15s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07000138463248333:  19% 146/765 [02:41<11:51,  1.15s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07000138463248333:  19% 147/765 [02:42<11:22,  1.10s/it]\u001b[A\u001b[A\n",
            " 19% 147/765 [02:42<11:22,  1.10s/it]\u001b[A\n",
            "\n",
            "train loss: 0.06989748718305713:  19% 147/765 [02:42<11:22,  1.10s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.06989748718305713:  19% 148/765 [02:43<11:50,  1.15s/it]\u001b[A\u001b[A\n",
            " 19% 148/765 [02:43<11:50,  1.15s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07012842523210959:  19% 148/765 [02:43<11:50,  1.15s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07012842523210959:  19% 149/765 [02:44<11:22,  1.11s/it]\u001b[A\u001b[A\n",
            " 19% 149/765 [02:44<11:22,  1.11s/it]\u001b[A\n",
            "\n",
            "train loss: 0.07000226980612782:  19% 149/765 [02:44<11:22,  1.11s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.07000226980612782:  20% 150/765 [02:46<11:48,  1.15s/it]\u001b[A\u001b[A\n",
            " 20% 150/765 [02:46<11:48,  1.15s/it]\u001b[A\n",
            "\n",
            "train loss: 0.06992935397351782:  20% 150/765 [02:46<11:48,  1.15s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.06992935397351782:  20% 151/765 [02:47<11:20,  1.11s/it]\u001b[A\u001b[A\n",
            " 20% 151/765 [02:47<11:20,  1.11s/it]\u001b[A\n",
            "\n",
            "train loss: 0.06994122960635565:  20% 151/765 [02:47<11:20,  1.11s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.06994122960635565:  20% 152/765 [02:48<11:44,  1.15s/it]\u001b[A\u001b[A\n",
            " 20% 152/765 [02:48<11:44,  1.15s/it]\u001b[A\n",
            "\n",
            "train loss: 0.06980971568631694:  20% 152/765 [02:48<11:44,  1.15s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.06980971568631694:  20% 153/765 [02:49<11:12,  1.10s/it]\u001b[A\u001b[A\n",
            " 20% 153/765 [02:49<11:12,  1.10s/it]\u001b[A\n",
            "\n",
            "train loss: 0.06969763176040907:  20% 153/765 [02:49<11:12,  1.10s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.06969763176040907:  20% 154/765 [02:50<11:37,  1.14s/it]\u001b[A\u001b[A\n",
            " 20% 154/765 [02:50<11:37,  1.14s/it]\u001b[A\n",
            "\n",
            "train loss: 0.069615395116777:  20% 154/765 [02:50<11:37,  1.14s/it]  \u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.069615395116777:  20% 155/765 [02:51<11:10,  1.10s/it]\u001b[A\u001b[A\n",
            " 20% 155/765 [02:51<11:10,  1.10s/it]\u001b[A\n",
            "\n",
            "train loss: 0.06954214905178355:  20% 155/765 [02:51<11:10,  1.10s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.06954214905178355:  20% 156/765 [02:52<11:35,  1.14s/it]\u001b[A\u001b[A\n",
            " 20% 156/765 [02:52<11:35,  1.14s/it]\u001b[A\n",
            "\n",
            "train loss: 0.0693853733738741:  20% 156/765 [02:52<11:35,  1.14s/it] \u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.0693853733738741:  21% 157/765 [02:53<11:07,  1.10s/it]\u001b[A\u001b[A\n",
            " 21% 157/765 [02:53<11:07,  1.10s/it]\u001b[A\n",
            "\n",
            "train loss: 0.06930858141796034:  21% 157/765 [02:53<11:07,  1.10s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.06930858141796034:  21% 158/765 [02:54<11:34,  1.14s/it]\u001b[A\u001b[A\n",
            " 21% 158/765 [02:54<11:34,  1.14s/it]\u001b[A\n",
            "\n",
            "train loss: 0.06920532656456285:  21% 158/765 [02:54<11:34,  1.14s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.06920532656456285:  21% 159/765 [02:55<11:07,  1.10s/it]\u001b[A\u001b[A\n",
            " 21% 159/765 [02:55<11:07,  1.10s/it]\u001b[A\n",
            "\n",
            "train loss: 0.06917901726662175:  21% 159/765 [02:55<11:07,  1.10s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.06917901726662175:  21% 160/765 [02:57<11:33,  1.15s/it]\u001b[A\u001b[A\n",
            " 21% 160/765 [02:57<11:33,  1.15s/it]\u001b[A\n",
            "\n",
            "train loss: 0.06908993260585702:  21% 160/765 [02:57<11:33,  1.15s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.06908993260585702:  21% 161/765 [02:58<11:03,  1.10s/it]\u001b[A\u001b[A\n",
            " 21% 161/765 [02:58<11:03,  1.10s/it]\u001b[A\n",
            "\n",
            "train loss: 0.06913516902428421:  21% 161/765 [02:58<11:03,  1.10s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.06913516902428421:  21% 162/765 [02:59<11:27,  1.14s/it]\u001b[A\u001b[A\n",
            " 21% 162/765 [02:59<11:27,  1.14s/it]\u001b[A\n",
            "\n",
            "train loss: 0.06903182582377836:  21% 162/765 [02:59<11:27,  1.14s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.06903182582377836:  21% 163/765 [03:00<10:59,  1.10s/it]\u001b[A\u001b[A\n",
            " 21% 163/765 [03:00<10:59,  1.10s/it]\u001b[A\n",
            "\n",
            "train loss: 0.06894620718788698:  21% 163/765 [03:00<10:59,  1.10s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.06894620718788698:  21% 164/765 [03:01<11:24,  1.14s/it]\u001b[A\u001b[A\n",
            " 21% 164/765 [03:01<11:24,  1.14s/it]\u001b[A\n",
            "\n",
            "train loss: 0.06887488481134357:  21% 164/765 [03:01<11:24,  1.14s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.06887488481134357:  22% 165/765 [03:02<10:56,  1.09s/it]\u001b[A\u001b[A\n",
            " 22% 165/765 [03:02<10:56,  1.09s/it]\u001b[A\n",
            "\n",
            "train loss: 0.06878553670125477:  22% 165/765 [03:02<10:56,  1.09s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.06878553670125477:  22% 166/765 [03:03<11:23,  1.14s/it]\u001b[A\u001b[A\n",
            " 22% 166/765 [03:03<11:23,  1.14s/it]\u001b[A\n",
            "\n",
            "train loss: 0.0686239473218749:  22% 166/765 [03:03<11:23,  1.14s/it] \u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.0686239473218749:  22% 167/765 [03:04<10:55,  1.10s/it]\u001b[A\u001b[A\n",
            " 22% 167/765 [03:04<10:55,  1.10s/it]\u001b[A\n",
            "\n",
            "train loss: 0.06861608957838335:  22% 167/765 [03:04<10:55,  1.10s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.06861608957838335:  22% 168/765 [03:06<11:22,  1.14s/it]\u001b[A\u001b[A\n",
            " 22% 168/765 [03:06<11:22,  1.14s/it]\u001b[A\n",
            "\n",
            "train loss: 0.06851348826949973:  22% 168/765 [03:06<11:22,  1.14s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.06851348826949973:  22% 169/765 [03:07<10:54,  1.10s/it]\u001b[A\u001b[A\n",
            " 22% 169/765 [03:07<10:54,  1.10s/it]\u001b[A\n",
            "\n",
            "train loss: 0.0684511031150906:  22% 169/765 [03:07<10:54,  1.10s/it] \u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.0684511031150906:  22% 170/765 [03:08<11:18,  1.14s/it]\u001b[A\u001b[A\n",
            " 22% 170/765 [03:08<11:18,  1.14s/it]\u001b[A\n",
            "\n",
            "train loss: 0.06838000540018958:  22% 170/765 [03:08<11:18,  1.14s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.06838000540018958:  22% 171/765 [03:09<10:51,  1.10s/it]\u001b[A\u001b[A\n",
            " 22% 171/765 [03:09<10:51,  1.10s/it]\u001b[A\n",
            "\n",
            "train loss: 0.06843893918922248:  22% 171/765 [03:09<10:51,  1.10s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.06843893918922248:  22% 172/765 [03:10<11:14,  1.14s/it]\u001b[A\u001b[A\n",
            " 22% 172/765 [03:10<11:14,  1.14s/it]\u001b[A\n",
            "\n",
            "train loss: 0.06839255400023661:  22% 172/765 [03:10<11:14,  1.14s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.06839255400023661:  23% 173/765 [03:11<10:45,  1.09s/it]\u001b[A\u001b[A\n",
            " 23% 173/765 [03:11<10:45,  1.09s/it]\u001b[A\n",
            "\n",
            "train loss: 0.06827737301092789:  23% 173/765 [03:11<10:45,  1.09s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.06827737301092789:  23% 174/765 [03:12<11:09,  1.13s/it]\u001b[A\u001b[A\n",
            " 23% 174/765 [03:12<11:09,  1.13s/it]\u001b[A\n",
            "\n",
            "train loss: 0.0681881305183573:  23% 174/765 [03:12<11:09,  1.13s/it] \u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.0681881305183573:  23% 175/765 [03:13<10:43,  1.09s/it]\u001b[A\u001b[A\n",
            " 23% 175/765 [03:13<10:43,  1.09s/it]\u001b[A\n",
            "\n",
            "train loss: 0.06806155407535178:  23% 175/765 [03:13<10:43,  1.09s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.06806155407535178:  23% 176/765 [03:15<11:07,  1.13s/it]\u001b[A\u001b[A\n",
            " 23% 176/765 [03:15<11:07,  1.13s/it]\u001b[A\n",
            "\n",
            "train loss: 0.06807831978023221:  23% 176/765 [03:15<11:07,  1.13s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.06807831978023221:  23% 177/765 [03:16<10:39,  1.09s/it]\u001b[A\u001b[A\n",
            " 23% 177/765 [03:16<10:39,  1.09s/it]\u001b[A\n",
            "\n",
            "train loss: 0.0680753807405715:  23% 177/765 [03:16<10:39,  1.09s/it] \u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.0680753807405715:  23% 178/765 [03:17<11:03,  1.13s/it]\u001b[A\u001b[A\n",
            " 23% 178/765 [03:17<11:03,  1.13s/it]\u001b[A\n",
            "\n",
            "train loss: 0.06816965758570293:  23% 178/765 [03:17<11:03,  1.13s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.06816965758570293:  23% 179/765 [03:18<10:35,  1.08s/it]\u001b[A\u001b[A\n",
            " 23% 179/765 [03:18<10:35,  1.08s/it]\u001b[A\n",
            "\n",
            "train loss: 0.06805503010937122:  23% 179/765 [03:18<10:35,  1.08s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.06805503010937122:  24% 180/765 [03:19<11:05,  1.14s/it]\u001b[A\u001b[A\n",
            " 24% 180/765 [03:19<11:05,  1.14s/it]\u001b[A\n",
            "\n",
            "train loss: 0.06807208301809926:  24% 180/765 [03:19<11:05,  1.14s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.06807208301809926:  24% 181/765 [03:20<10:37,  1.09s/it]\u001b[A\u001b[A\n",
            " 24% 181/765 [03:20<10:37,  1.09s/it]\u001b[A\n",
            "\n",
            "train loss: 0.0680137254678495:  24% 181/765 [03:20<10:37,  1.09s/it] \u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.0680137254678495:  24% 182/765 [03:21<11:02,  1.14s/it]\u001b[A\u001b[A\n",
            " 24% 182/765 [03:21<11:02,  1.14s/it]\u001b[A\n",
            "\n",
            "train loss: 0.06798635417554569:  24% 182/765 [03:21<11:02,  1.14s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.06798635417554569:  24% 183/765 [03:22<10:35,  1.09s/it]\u001b[A\u001b[A\n",
            " 24% 183/765 [03:22<10:35,  1.09s/it]\u001b[A\n",
            "\n",
            "train loss: 0.06795465989455662:  24% 183/765 [03:22<10:35,  1.09s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.06795465989455662:  24% 184/765 [03:23<10:57,  1.13s/it]\u001b[A\u001b[A\n",
            " 24% 184/765 [03:23<10:57,  1.13s/it]\u001b[A\n",
            "\n",
            "train loss: 0.06798104061643877:  24% 184/765 [03:23<10:57,  1.13s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.06798104061643877:  24% 185/765 [03:24<10:30,  1.09s/it]\u001b[A\u001b[A\n",
            " 24% 185/765 [03:24<10:30,  1.09s/it]\u001b[A\n",
            "\n",
            "train loss: 0.0678736659975068:  24% 185/765 [03:24<10:30,  1.09s/it] \u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.0678736659975068:  24% 186/765 [03:26<10:55,  1.13s/it]\u001b[A\u001b[A\n",
            " 24% 186/765 [03:26<10:55,  1.13s/it]\u001b[A\n",
            "\n",
            "train loss: 0.06777691382974867:  24% 186/765 [03:26<10:55,  1.13s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.06777691382974867:  24% 187/765 [03:27<10:30,  1.09s/it]\u001b[A\u001b[A\n",
            " 24% 187/765 [03:27<10:30,  1.09s/it]\u001b[A\n",
            "\n",
            "train loss: 0.0677685207951276:  24% 187/765 [03:27<10:30,  1.09s/it] \u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.0677685207951276:  25% 188/765 [03:28<10:55,  1.14s/it]\u001b[A\u001b[A\n",
            " 25% 188/765 [03:28<10:55,  1.14s/it]\u001b[A\n",
            "\n",
            "train loss: 0.06782737020105917:  25% 188/765 [03:28<10:55,  1.14s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.06782737020105917:  25% 189/765 [03:29<10:30,  1.09s/it]\u001b[A\u001b[A\n",
            " 25% 189/765 [03:29<10:30,  1.09s/it]\u001b[A\n",
            "\n",
            "train loss: 0.06784648557129518:  25% 189/765 [03:29<10:30,  1.09s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.06784648557129518:  25% 190/765 [03:30<10:52,  1.14s/it]\u001b[A\u001b[A\n",
            " 25% 190/765 [03:30<10:52,  1.14s/it]\u001b[A\n",
            "\n",
            "train loss: 0.06788685230146113:  25% 190/765 [03:30<10:52,  1.14s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.06788685230146113:  25% 191/765 [03:31<10:27,  1.09s/it]\u001b[A\u001b[A\n",
            " 25% 191/765 [03:31<10:27,  1.09s/it]\u001b[A\n",
            "\n",
            "train loss: 0.06771643661177128:  25% 191/765 [03:31<10:27,  1.09s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.06771643661177128:  25% 192/765 [03:32<10:52,  1.14s/it]\u001b[A\u001b[A\n",
            " 25% 192/765 [03:32<10:52,  1.14s/it]\u001b[A\n",
            "\n",
            "train loss: 0.06772809687633223:  25% 192/765 [03:32<10:52,  1.14s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.06772809687633223:  25% 193/765 [03:33<10:25,  1.09s/it]\u001b[A\u001b[A\n",
            " 25% 193/765 [03:33<10:25,  1.09s/it]\u001b[A\n",
            "\n",
            "train loss: 0.06768486193752814:  25% 193/765 [03:33<10:25,  1.09s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.06768486193752814:  25% 194/765 [03:35<10:49,  1.14s/it]\u001b[A\u001b[A\n",
            " 25% 194/765 [03:35<10:49,  1.14s/it]\u001b[A\n",
            "\n",
            "train loss: 0.06760189989965755:  25% 194/765 [03:35<10:49,  1.14s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.06760189989965755:  25% 195/765 [03:36<10:24,  1.10s/it]\u001b[A\u001b[A\n",
            " 25% 195/765 [03:36<10:24,  1.10s/it]\u001b[A\n",
            "\n",
            "train loss: 0.06751184230909134:  25% 195/765 [03:36<10:24,  1.10s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.06751184230909134:  26% 196/765 [03:37<10:47,  1.14s/it]\u001b[A\u001b[A\n",
            " 26% 196/765 [03:37<10:47,  1.14s/it]\u001b[A\n",
            "\n",
            "train loss: 0.06747054613233373:  26% 196/765 [03:37<10:47,  1.14s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.06747054613233373:  26% 197/765 [03:38<10:22,  1.10s/it]\u001b[A\u001b[A\n",
            " 26% 197/765 [03:38<10:22,  1.10s/it]\u001b[A\n",
            "\n",
            "train loss: 0.06734490275931389:  26% 197/765 [03:38<10:22,  1.10s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.06734490275931389:  26% 198/765 [03:39<10:43,  1.14s/it]\u001b[A\u001b[A\n",
            " 26% 198/765 [03:39<10:43,  1.14s/it]\u001b[A\n",
            "\n",
            "train loss: 0.06729912818550612:  26% 198/765 [03:39<10:43,  1.14s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.06729912818550612:  26% 199/765 [03:40<10:20,  1.10s/it]\u001b[A\u001b[A\n",
            " 26% 199/765 [03:40<10:20,  1.10s/it]\u001b[A\n",
            "\n",
            "train loss: 0.06726076050039062:  26% 199/765 [03:40<10:20,  1.10s/it]\u001b[A\u001b[A\n",
            "\n",
            "train loss: 0.06726076050039062:  26% 200/765 [03:41<10:42,  1.14s/it]\u001b[A\u001b[A\n",
            " 26% 200/765 [03:41<10:42,  1.14s/it]\u001b[A\n",
            "\n",
            "train loss: 0.06729331061709672:  26% 200/765 [03:41<10:42,  1.14s/it]\u001b[A\u001b[ATraceback (most recent call last):\n",
            "  File \"run_classifier_bert.py\", line 694, in <module>\n",
            "    main()\n",
            "  File \"run_classifier_bert.py\", line 671, in main\n",
            "    global_step, tr_loss = train(args, train_datasets, model, tokenizer)\n",
            "  File \"run_classifier_bert.py\", line 321, in train\n",
            "    outputs = model(**inputs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/drive/My Drive/Colab Notebooks/MMM-MCQA-master/pytorch_pretrained_bert/modeling.py\", line 1909, in forward\n",
            "    head_mask=head_mask)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/drive/My Drive/Colab Notebooks/MMM-MCQA-master/pytorch_pretrained_bert/modeling.py\", line 901, in forward\n",
            "    head_mask=head_mask)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/drive/My Drive/Colab Notebooks/MMM-MCQA-master/pytorch_pretrained_bert/modeling.py\", line 506, in forward\n",
            "    hidden_states = layer_module(hidden_states, attention_mask, head_mask[i])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/drive/My Drive/Colab Notebooks/MMM-MCQA-master/pytorch_pretrained_bert/modeling.py\", line 488, in forward\n",
            "    layer_output = self.output(intermediate_output, attention_output)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/drive/My Drive/Colab Notebooks/MMM-MCQA-master/pytorch_pretrained_bert/modeling.py\", line 470, in forward\n",
            "    hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/drive/My Drive/Colab Notebooks/MMM-MCQA-master/pytorch_pretrained_bert/modeling.py\", line 290, in forward\n",
            "    x = (x - u) / torch.sqrt(s + self.variance_epsilon)\n",
            "KeyboardInterrupt\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "Epoch:   0% 0/8 [03:41<?, ?it/s]\n",
            "train loss: 0.06729331061709672:  26% 200/765 [03:41<10:26,  1.11s/it]\n",
            " 26% 200/765 [03:41<10:26,  1.11s/it]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}